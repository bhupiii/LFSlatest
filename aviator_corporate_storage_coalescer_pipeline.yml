groups:
- jobs:
  - storage-development-all
  name: coalesce-storage-all
- jobs:
  - manifests-development-all
  name: coalesce-manifests-all
- jobs:
  - storage-development-audit-per-partition
  - storage-development-equalities-per-partition
  - storage-development-main-per-partition
  name: coalesce-storage-per-partition
- jobs:
  - manifests-development-audit-per-partition
  - manifests-development-equalities-per-partition
  - manifests-development-main-per-partition
  name: coalesce-manifests-per-partition
- jobs:
  - update-pipeline-corporate-storage-coalescer
  name: update-pipeline
jobs:
- max_in_flight: 1
  name: manifests-development-all
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: audit
        FILE_TYPE: manifests
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-audit-manifests
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: audit
        FILE_TYPE: manifests
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-audit-manifests
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: equalities
        FILE_TYPE: manifests
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-equalities-manifests
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: equalities
        FILE_TYPE: manifests
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-equalities-manifests
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: main
        FILE_TYPE: manifests
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-main-manifests
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: main
        FILE_TYPE: manifests
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-main-manifests
- max_in_flight: 1
  name: manifests-development-audit-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-audit-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-audit-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-audit-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-audit-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-audit-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-audit-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-audit-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-audit-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-audit-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-audit-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-audit-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-audit-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-audit-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-audit-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-audit-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-audit-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-audit-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-audit-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-audit-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-audit-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-audit-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-audit-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-audit-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-audit-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-audit-manifests-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-audit-manifests-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-audit-manifests-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-audit-manifests-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-audit-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-audit-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-audit-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-audit-manifests-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-audit-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-audit-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-audit-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-audit-manifests-partition-nineteen
- max_in_flight: 1
  name: manifests-development-equalities-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-equalities-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-equalities-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-equalities-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-equalities-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-equalities-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-equalities-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-equalities-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-equalities-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-equalities-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-equalities-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-equalities-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-equalities-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-equalities-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-equalities-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-equalities-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-equalities-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-equalities-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-equalities-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-equalities-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-equalities-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-equalities-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-equalities-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-equalities-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-equalities-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-equalities-manifests-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-equalities-manifests-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-equalities-manifests-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-equalities-manifests-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-equalities-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-equalities-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-equalities-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-equalities-manifests-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-equalities-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-equalities-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-equalities-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-equalities-manifests-partition-nineteen
- max_in_flight: 1
  name: manifests-development-main-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-main-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-main-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-main-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-main-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-main-manifests-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-main-manifests-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-main-manifests-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-main-manifests-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-main-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-main-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-main-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-main-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-main-manifests-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-main-manifests-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-main-manifests-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-main-manifests-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-main-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-main-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-main-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-main-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-main-manifests-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-main-manifests-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-main-manifests-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-main-manifests-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-main-manifests-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-main-manifests-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-main-manifests-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-main-manifests-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-main-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-main-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-main-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-main-manifests-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-main-manifests-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-main-manifests-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-main-manifests-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: manifests
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-main-manifests-partition-nineteen
- max_in_flight: 1
  name: storage-development-all
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: audit
        FILE_TYPE: storage
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-audit-storage
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: audit
        FILE_TYPE: storage
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-audit-storage
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: equalities
        FILE_TYPE: storage
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-equalities-storage
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: equalities
        FILE_TYPE: storage
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-equalities-storage
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      - name: meta
      - name: terraform-output-ingest
      - name: terraform-output-ingest-consumers
      - name: terraform-output-internal-compute
      outputs:
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: main
        FILE_TYPE: storage
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role
          set +x

          function set_parameters_for_job {
            if [[ -z "${DATE_TO_RUN}" ]]; then
              DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
              echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
            fi

            if [[ -z "${PARTITION_NUMBER}" ]]; then
              export PARTITION_NUMBER="-1"
              echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
            fi

            if [[ -z "${THREAD_COUNT}" ]]; then
              export THREAD_COUNT="0"
              echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
            fi

            echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
              \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
              \"partition\": \"${PARTITION_NUMBER}\", \
              \"threads\": \"${THREAD_COUNT}\", \
              \"max-files\": \"${MAX_SIZE_FILES}\", \
              \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
          }

          function set_common_variables {
            echo "Setting common variables"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main common variables"
              export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
              export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
          }

          function set_manifest_variables {
            echo "Setting variables for manifests"
            export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          function set_corporate_storage_variables {
            echo "Setting variables for corporate storage"
            export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
            echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

            if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
              echo "Setting equalities base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
              echo "Setting audit base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
            elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
              echo "Setting main base s3 prefix"
              export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
            else
              echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
              exit 1
            fi

            echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
          }

          set_common_variables

          if [[ "${FILE_TYPE}" == "manifests" ]]; then
            set_manifest_variables
          else
            set_corporate_storage_variables
          fi

          set_parameters_for_job
        dir: dataworks-corporate-storage-coalescence
        path: sh
    output_mapping:
      job-parameters: job-parameters-all-partitions
    task: set-coalescer-parameters-main-storage
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_python_boto_behave_repository))
          tag: ((dataworks.docker_python_boto_behave_version))
        type: docker-image
      inputs:
      - name: meta
      - name: job-parameters
      params:
        ASSUME_DURATION: 43200
        AWS_DEFAULT_REGION: ((dataworks.aws_region))
        AWS_REGION: ((dataworks.aws_region))
        AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
        CORPORATE_STORAGE_TYPE: main
        FILE_TYPE: storage
        TIMEOUT: 43200
      platform: linux
      run:
        args:
        - -exc
        - |
          source /assume-role

          function set_job_parameters {
            export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
          }

          function submit_job {
            pipeline_name=`cat "../meta/build_pipeline_name"`
            job_name=`cat "../meta/build_job_name"`
            build_number=`cat "../meta/build_name"`
            build_number_safe=`echo ${build_number/./-}`
            set +x
            export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
              --job-definition "batch_corporate_storage_coalescer_job" \
              --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
              --parameters "${1}" \
              | jq -e --raw-output .jobId)
            set -x
          }

          function wait_for_job_completion {
            i=0
            while [[ ${i} -le ${TIMEOUT} ]]
            do
              status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
              case $status in
                FAILED)
                  echo "job failed"
                  exit 1
                  ;;
                SUCCEEDED)
                  echo "job succeeded"
                  exit 0
                  ;;
                SUBMITTED)
                  echo "job is currently ${status}"
                  ;;
                PENDING)
                  echo "job is currently ${status}"
                  ;;
                RUNNABLE)
                  echo "job is currently ${status}"
                  ;;
                STARTING)
                  echo "job is currently ${status}"
                  ;;
                RUNNING)
                  echo "job is currently ${status}"
                  ;;
                *)
                  echo "unknown status $status"
                  exit 1
                  ;;
              esac
              i=$((i+1))
              sleep 60
            done

            echo "Timed out waiting for job to complete"
            exit 1
          }

          echo "Setting job parameters"
          set_job_parameters
          if [[ -z "${JOB_PARAMETERS}" ]]; then
            echo "Error retrieving job parameters"
            exit 1
          fi
          echo "Job parameters set to '${JOB_PARAMETERS}'"

          echo "Submitting job"
          submit_job "${JOB_PARAMETERS}"
          if [[ -z "${JOB_ID}" ]]; then
            echo "Error submitting job, empty JOB_ID received"
            exit 1
          fi
          echo "Submitted job with id of '${JOB_ID}"

          echo "Waiting for job with id of '${JOB_ID}' to complete"
          wait_for_job_completion
          echo "Job with id of '${JOB_ID}' completed successfully"
        dir: job-parameters
        path: sh
    input_mapping:
      job-parameters: job-parameters-all-partitions
    task: run-coalescer-main-storage
- max_in_flight: 1
  name: storage-development-audit-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-audit-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-audit-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-audit-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-audit-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-audit-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-audit-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-audit-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-audit-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-audit-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-audit-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-audit-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-audit-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-audit-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-audit-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-audit-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-audit-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-audit-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-audit-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-audit-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-audit-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-audit-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-audit-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-audit-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-audit-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-audit-storage-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-audit-storage-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-audit-storage-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-audit-storage-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-audit-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-audit-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-audit-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-audit-storage-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-audit-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-audit-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-audit-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: audit
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-audit-storage-partition-nineteen
- max_in_flight: 1
  name: storage-development-equalities-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-equalities-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-equalities-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-equalities-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-equalities-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-equalities-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-equalities-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-equalities-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-equalities-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-equalities-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-equalities-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-equalities-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-equalities-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-equalities-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-equalities-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-equalities-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-equalities-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-equalities-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-equalities-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-equalities-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-equalities-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-equalities-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-equalities-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-equalities-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-equalities-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-equalities-storage-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-equalities-storage-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-equalities-storage-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-equalities-storage-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-equalities-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-equalities-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-equalities-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-equalities-storage-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-equalities-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-equalities-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-equalities-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: equalities
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-equalities-storage-partition-nineteen
- max_in_flight: 1
  name: storage-development-main-per-partition
  plan:
  - in_parallel:
    - put: meta
      resource: meta-development
    - get: utc-1am
      trigger: true
    - get: dataworks-corporate-storage-coalescence
      trigger: false
    - get: aws-ingestion
      trigger: false
    - get: aws-internal-compute
      trigger: false
    - get: dataworks-aws-ingest-consumers
      trigger: false
  - config:
      image_resource:
        source:
          repository: dwpdigital/jinja-yaml-aws
          tag: 0.0.19
          version: 0.0.19
        type: docker-image
      inputs:
      - name: dataworks-aws-ingest-consumers
      outputs:
      - name: terraform-bootstrap
      platform: linux
      run:
        args:
        - -exc
        - |
          python bootstrap_terraform.py
          cp terraform.tf ../terraform-bootstrap
        dir: dataworks-aws-ingest-consumers
        path: sh
    params:
      AWS_REGION: ((dataworks.aws_region))
    task: terraform-bootstrap
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
    - config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
          TF_WORKSPACE: default
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-main-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-main-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-main-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-main-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-main-storage-partition-zero
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-main-storage-partition-one
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-main-storage-partition-two
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-main-storage-partition-three
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-main-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-main-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-main-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-main-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-main-storage-partition-four
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-main-storage-partition-five
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-main-storage-partition-six
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-main-storage-partition-seven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-main-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-main-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-main-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-main-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-main-storage-partition-eight
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-main-storage-partition-nine
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-main-storage-partition-ten
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-main-storage-partition-eleven
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-main-storage-partition-twelve
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-main-storage-partition-thirteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-main-storage-partition-fourteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-main-storage-partition-fifteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-main-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-main-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-main-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-main-storage-partition-nineteen
  - in_parallel:
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-main-storage-partition-sixteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-main-storage-partition-seventeen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-main-storage-partition-eighteen
    - config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          AWS_ROLE_ARN: arn:aws:iam::((aws_account.development)):role/ci
          CORPORATE_STORAGE_TYPE: main
          FILE_TYPE: storage
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-main-storage-partition-nineteen
- name: update-pipeline-corporate-storage-coalescer
  plan:
  - get: dataworks-corporate-storage-coalescence
    resource: dataworks-corporate-storage-coalescence-update-pipeline
    trigger: true
  - config:
      image_resource:
        source:
          repository: ((dataworks.docker_aviator_repository))
          version: ((dataworks.docker_aviator_version))
        type: docker-image
      inputs:
      - name: dataworks-corporate-storage-coalescence
      outputs:
      - name: pipeline
      platform: linux
      run:
        args:
        - -exc
        - |
          sed -i 's/fly/nofly/' aviator-corporate-storage-coalescence.yml
          /usr/bin/aviator -f aviator-corporate-storage-coalescence.yml
          mv aviator_corporate_storage_coalescence_pipeline.yml ../pipeline
        dir: dataworks-corporate-storage-coalescence
        path: sh
    task: aviator
  - file: pipeline/aviator_corporate_storage_coalescence_pipeline.yml
    set_pipeline: corporate-storage-coalescence
meta-corporate-storage-coalescer:
  plan:
    run-coalescer:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      task: run-coalescer
    run-coalescer-all-partitions:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-all-partitions
      task: run-coalescer-all-partitions
    set-coalescer-parameters:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      task: set-coalescer-parameters
    set-coalescer-parameters-all-partitions:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-all-partitions
      task: set-coalescer-parameters-all-partitions
    terraform-bootstrap:
      config:
        image_resource:
          source:
            repository: dwpdigital/jinja-yaml-aws
            tag: 0.0.19
            version: 0.0.19
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        outputs:
        - name: terraform-bootstrap
        platform: linux
        run:
          args:
          - -exc
          - |
            python bootstrap_terraform.py
            cp terraform.tf ../terraform-bootstrap
          dir: dataworks-aws-ingest-consumers
          path: sh
      params:
        AWS_REGION: ((dataworks.aws_region))
      task: terraform-bootstrap
    terraform-common-config:
      config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        platform: linux
    terraform-output-ingest:
      config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-ingestion
        outputs:
        - name: terraform-output-ingest
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
          path: sh
      task: terraform-output-ingest
    terraform-output-ingest-consumers:
      config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: dataworks-aws-ingest-consumers
        - name: terraform-bootstrap
        outputs:
        - name: terraform-output-ingest-consumers
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        platform: linux
        run:
          args:
          - -exc
          - |
            cp ../terraform-bootstrap/terraform.tf .
            ls -la terraform.tf
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
          path: sh
      task: terraform-output-ingest-consumers
    terraform-output-internal-compute:
      config:
        image_resource:
          source:
            repository: ((dataworks.terraform_repository))
            tag: ((dataworks.terraform_version))
            version: ((dataworks.terraform_version))
          type: docker-image
        inputs:
        - name: aws-internal-compute
        outputs:
        - name: terraform-output-internal-compute
        params:
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_INPUT: false
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))
        platform: linux
        run:
          args:
          - -exc
          - |
            terraform workspace show
            terraform init
            terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
          path: sh
      task: terraform-output-internal-compute
meta-run-coalescer-per-partition:
  plan:
    run-coalescer-partition-eight:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 8
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eight
      task: run-coalescer-partition-eight
    run-coalescer-partition-eighteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 18
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: run-coalescer-partition-eighteen
    run-coalescer-partition-eleven:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 11
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-eleven
      task: run-coalescer-partition-eleven
    run-coalescer-partition-fifteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 15
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: run-coalescer-partition-fifteen
    run-coalescer-partition-five:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 5
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-five
      task: run-coalescer-partition-five
    run-coalescer-partition-four:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 4
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-four
      task: run-coalescer-partition-four
    run-coalescer-partition-fourteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 14
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: run-coalescer-partition-fourteen
    run-coalescer-partition-nine:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 9
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nine
      task: run-coalescer-partition-nine
    run-coalescer-partition-nineteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 19
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: run-coalescer-partition-nineteen
    run-coalescer-partition-one:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 1
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-one
      task: run-coalescer-partition-one
    run-coalescer-partition-seven:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 7
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seven
      task: run-coalescer-partition-seven
    run-coalescer-partition-seventeen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 17
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: run-coalescer-partition-seventeen
    run-coalescer-partition-six:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 6
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-six
      task: run-coalescer-partition-six
    run-coalescer-partition-sixteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 16
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: run-coalescer-partition-sixteen
    run-coalescer-partition-ten:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 10
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-ten
      task: run-coalescer-partition-ten
    run-coalescer-partition-thirteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 13
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: run-coalescer-partition-thirteen
    run-coalescer-partition-three:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 3
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-three
      task: run-coalescer-partition-three
    run-coalescer-partition-twelve:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 12
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-twelve
      task: run-coalescer-partition-twelve
    run-coalescer-partition-two:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 2
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-two
      task: run-coalescer-partition-two
    run-coalescer-partition-zero:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: meta
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 0
          TIMEOUT: 43200
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role

            function set_job_parameters {
              export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
            }

            function submit_job {
              pipeline_name=`cat "../meta/build_pipeline_name"`
              job_name=`cat "../meta/build_job_name"`
              build_number=`cat "../meta/build_name"`
              build_number_safe=`echo ${build_number/./-}`
              set +x
              export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                --job-definition "batch_corporate_storage_coalescer_job" \
                --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                --parameters "${1}" \
                | jq -e --raw-output .jobId)
              set -x
            }

            function wait_for_job_completion {
              i=0
              while [[ ${i} -le ${TIMEOUT} ]]
              do
                status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                case $status in
                  FAILED)
                    echo "job failed"
                    exit 1
                    ;;
                  SUCCEEDED)
                    echo "job succeeded"
                    exit 0
                    ;;
                  SUBMITTED)
                    echo "job is currently ${status}"
                    ;;
                  PENDING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNABLE)
                    echo "job is currently ${status}"
                    ;;
                  STARTING)
                    echo "job is currently ${status}"
                    ;;
                  RUNNING)
                    echo "job is currently ${status}"
                    ;;
                  *)
                    echo "unknown status $status"
                    exit 1
                    ;;
                esac
                i=$((i+1))
                sleep 60
              done

              echo "Timed out waiting for job to complete"
              exit 1
            }

            echo "Setting job parameters"
            set_job_parameters
            if [[ -z "${JOB_PARAMETERS}" ]]; then
              echo "Error retrieving job parameters"
              exit 1
            fi
            echo "Job parameters set to '${JOB_PARAMETERS}'"

            echo "Submitting job"
            submit_job "${JOB_PARAMETERS}"
            if [[ -z "${JOB_ID}" ]]; then
              echo "Error submitting job, empty JOB_ID received"
              exit 1
            fi
            echo "Submitted job with id of '${JOB_ID}"

            echo "Waiting for job with id of '${JOB_ID}' to complete"
            wait_for_job_completion
            echo "Job with id of '${JOB_ID}' completed successfully"
          dir: job-parameters
          path: sh
      input_mapping:
        job-parameters: job-parameters-partition-zero
      task: run-coalescer-partition-zero
meta-set-parameters-per-partition:
  plan:
    set-coalescer-parameters-partition-eight:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 8
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eight
      task: set-coalescer-parameters-partition-eight
    set-coalescer-parameters-partition-eighteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 18
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eighteen
      task: set-coalescer-parameters-partition-eighteen
    set-coalescer-parameters-partition-eleven:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 11
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-eleven
      task: set-coalescer-parameters-partition-eleven
    set-coalescer-parameters-partition-fifteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 15
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fifteen
      task: set-coalescer-parameters-partition-fifteen
    set-coalescer-parameters-partition-five:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 5
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-five
      task: set-coalescer-parameters-partition-five
    set-coalescer-parameters-partition-four:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 4
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-four
      task: set-coalescer-parameters-partition-four
    set-coalescer-parameters-partition-fourteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 14
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-fourteen
      task: set-coalescer-parameters-partition-fourteen
    set-coalescer-parameters-partition-nine:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 9
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nine
      task: set-coalescer-parameters-partition-nine
    set-coalescer-parameters-partition-nineteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 19
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-nineteen
      task: set-coalescer-parameters-partition-nineteen
    set-coalescer-parameters-partition-one:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 1
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-one
      task: set-coalescer-parameters-partition-one
    set-coalescer-parameters-partition-seven:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 7
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seven
      task: set-coalescer-parameters-partition-seven
    set-coalescer-parameters-partition-seventeen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 17
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-seventeen
      task: set-coalescer-parameters-partition-seventeen
    set-coalescer-parameters-partition-six:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 6
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-six
      task: set-coalescer-parameters-partition-six
    set-coalescer-parameters-partition-sixteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 16
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-sixteen
      task: set-coalescer-parameters-partition-sixteen
    set-coalescer-parameters-partition-ten:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 10
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-ten
      task: set-coalescer-parameters-partition-ten
    set-coalescer-parameters-partition-thirteen:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 13
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-thirteen
      task: set-coalescer-parameters-partition-thirteen
    set-coalescer-parameters-partition-three:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 3
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-three
      task: set-coalescer-parameters-partition-three
    set-coalescer-parameters-partition-twelve:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 12
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-twelve
      task: set-coalescer-parameters-partition-twelve
    set-coalescer-parameters-partition-two:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 2
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-two
      task: set-coalescer-parameters-partition-two
    set-coalescer-parameters-partition-zero:
      config:
        image_resource:
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
          type: docker-image
        inputs:
        - name: dataworks-corporate-storage-coalescence
        - name: meta
        - name: terraform-output-ingest
        - name: terraform-output-ingest-consumers
        - name: terraform-output-internal-compute
        outputs:
        - name: job-parameters
        params:
          ASSUME_DURATION: 43200
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          AWS_REGION: ((dataworks.aws_region))
          PARTITION_NUMBER: 0
        platform: linux
        run:
          args:
          - -exc
          - |
            source /assume-role
            set +x

            function set_parameters_for_job {
              if [[ -z "${DATE_TO_RUN}" ]]; then
                DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
              fi

              if [[ -z "${PARTITION_NUMBER}" ]]; then
                export PARTITION_NUMBER="-1"
                echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
              fi

              if [[ -z "${THREAD_COUNT}" ]]; then
                export THREAD_COUNT="0"
                echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
              fi

              echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                \"partition\": \"${PARTITION_NUMBER}\", \
                \"threads\": \"${THREAD_COUNT}\", \
                \"max-files\": \"${MAX_SIZE_FILES}\", \
                \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
            }

            function set_common_variables {
              echo "Setting common variables"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main common variables"
                export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
            }

            function set_manifest_variables {
              echo "Setting variables for manifests"
              export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            function set_corporate_storage_variables {
              echo "Setting variables for corporate storage"
              export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
              echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

              if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                echo "Setting equalities base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                echo "Setting audit base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
              elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                echo "Setting main base s3 prefix"
                export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
              else
                echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                exit 1
              fi

              echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
            }

            set_common_variables

            if [[ "${FILE_TYPE}" == "manifests" ]]; then
              set_manifest_variables
            else
              set_corporate_storage_variables
            fi

            set_parameters_for_job
          dir: dataworks-corporate-storage-coalescence
          path: sh
      output_mapping:
        job-parameters: job-parameters-partition-zero
      task: set-coalescer-parameters-partition-zero
resource_types:
- name: meta
  source:
    repository: olhtbr/metadata-resource
    tag: 2.0.1
  type: docker-image
resources:
- check_every: 5m
  name: dataworks-corporate-storage-coalescence
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    uri: https://github.com/dwp/dataworks-corporate-storage-coalescence.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-corporate-storage-coalescence-update-pipeline
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    paths:
    - ci/utility/corporate-storage-coalescer/*
    - aviator-corporate-storage-coalescer.yml
    uri: https://github.com/dwp/dataworks-corporate-storage-coalescence.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: aws-ingestion
  source:
    api_endpoint: https://((dataworks.enterprise_github_url))/api/v3/
    branch: master
    password: ((dataworks-secrets.enterprise_github_pat))
    uri: https://((dataworks.enterprise_github_url))/dip/aws-ingestion.git
    username: ((dataworks.enterprise_github_username))
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: aws-internal-compute
  source:
    api_endpoint: https://((dataworks.enterprise_github_url))/api/v3/
    branch: master
    password: ((dataworks-secrets.enterprise_github_pat))
    uri: https://((dataworks.enterprise_github_url))/dip/aws-internal-compute.git
    username: ((dataworks.enterprise_github_username))
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- check_every: 5m
  name: dataworks-aws-ingest-consumers
  source:
    access_token: ((dataworks-secrets.concourse_github_pat))
    branch: master
    uri: https://github.com/dwp/dataworks-aws-ingest-consumers.git
  type: git
  webhook_token: ((dataworks.concourse_github_webhook_token))
- name: utc-1am
  source:
    location: UTC
    start: 1:00 AM
    stop: 1:05 AM
  type: time
- name: meta-development
  type: meta
