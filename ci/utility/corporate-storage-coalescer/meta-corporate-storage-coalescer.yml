meta-corporate-storage-coalescer:
  plan:
    set-coalescer-parameters-all-partitions:
      task: set-coalescer-parameters-all-partitions
      .: (( inject meta-corporate-storage-coalescer.plan.set-coalescer-parameters ))
      output_mapping:
        job-parameters: job-parameters-all-partitions

    set-coalescer-parameters:
      task: set-coalescer-parameters
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          ASSUME_DURATION: 43200
        run:
          dir: dataworks-corporate-storage-coalescence
          path: sh
          args:
            - -exc
            - |
              source /assume-role
              set +x

              function set_parameters_for_job {
                if [[ -z "${DATE_TO_RUN}" ]]; then
                  DATE_TO_RUN=$(date -d "$1" +'%Y/%m/%d')
                  echo "Defaulting to date of today, due to incoming date to run of '${DATE_TO_RUN}'"
                fi

                if [[ -z "${PARTITION_NUMBER}" ]]; then
                  export PARTITION_NUMBER="-1"
                  echo "Defaulting to partition number of -1, which means not set due to incoming partition number of '${PARTITION_NUMBER}'"
                fi

                if [[ -z "${THREAD_COUNT}" ]]; then
                  export THREAD_COUNT="0"
                  echo "Defaulting to thread count of 0, which means not set due to incoming thread count of '${THREAD_COUNT}'"
                fi

                echo "{\"s3-bucket-id\": \"${S3_BUCKET_ID}\", \
                  \"s3-prefix\": \"${S3_BASE_PREFIX}/${DATE_TO_RUN}\", \
                  \"partition\": \"${PARTITION_NUMBER}\", \
                  \"threads\": \"${THREAD_COUNT}\", \
                  \"max-files\": \"${MAX_SIZE_FILES}\", \
                  \"max-size\": \"${MAX_SIZE_BYTES}\"}" > ../job-parameters/parameters.txt
              }

              function set_common_variables {
                echo "Setting common variables"

                if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                  echo "Setting equalities common variables"
                  export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.equalities')
                  export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.equalities')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                  echo "Setting audit common variables"
                  export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.audit')
                  export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.audit')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                  echo "Setting main common variables"
                  export MAX_SIZE_FILES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_files.main')
                  export MAX_SIZE_BYTES=$(cat ../terraform-output-ingest-consumers/outputs.json | jq -r '.k2hb_corporate_storage_coalesce_values.value.max_size_bytes.main')
                else
                  echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                  exit 1
                fi

                echo "Set MAX_SIZE_FILES to '${MAX_SIZE_FILES}' and MAX_SIZE_BYTES to '${MAX_SIZE_BYTES}'"
              }

              function set_manifest_variables {
                echo "Setting variables for manifests"
                export S3_BUCKET_ID=$(cat ../terraform-output-internal-compute/outputs.json | jq -r '.manifest_bucket.value.id')
                echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

                if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                  echo "Setting equalities base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.equality_prefix')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                  echo "Setting audit base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.audit_prefix')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                  echo "Setting main base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.k2hb_manifest_write_locations.value.main_prefix')
                else
                  echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                  exit 1
                fi

                echo "Set S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
              }

              function set_corporate_storage_variables {
                echo "Setting variables for corporate storage"
                export S3_BUCKET_ID=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_storage_bucket.value.id')
                echo "Set S3_BUCKET_ID to '${S3_BUCKET_ID}'"

                if [ "${CORPORATE_STORAGE_TYPE}" == "equalities" ]; then
                  echo "Setting equalities base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_equalities')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "audit" ]; then
                  echo "Setting audit base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_audit')
                elif [ "${CORPORATE_STORAGE_TYPE}" == "main" ]; then
                  echo "Setting main base s3 prefix"
                  export S3_BASE_PREFIX=$(cat ../terraform-output-ingest/outputs.json | jq -r '.corporate_data_loader.value.s3_base_prefix_ucfs')
                else
                  echo "Exiting abnormally due to unrecognised corporate storage type of '${CORPORATE_STORAGE_TYPE}'"
                  exit 1
                fi

                echo "S3_BASE_PREFIX to '${S3_BASE_PREFIX}'"
              }

              set_common_variables

              if [[ "${FILE_TYPE}" == "manifests" ]]; then
                set_manifest_variables
              else
                set_corporate_storage_variables
              fi

              set_parameters_for_job
        inputs:
          - name: dataworks-corporate-storage-coalescence
          - name: meta
          - name: terraform-output-ingest
          - name: terraform-output-ingest-consumers
          - name: terraform-output-internal-compute
        outputs:
          - name: job-parameters

    run-coalescer-all-partitions:
      task: run-coalescer-all-partitions
      .: (( inject meta-corporate-storage-coalescer.plan.run-coalescer ))
      input_mapping:
        job-parameters: job-parameters-all-partitions

    run-coalescer:
      task: run-coalescer
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.docker_python_boto_behave_repository))
            tag: ((dataworks.docker_python_boto_behave_version))
        params:
          AWS_REGION: ((dataworks.aws_region))
          AWS_DEFAULT_REGION: ((dataworks.aws_region))
          ASSUME_DURATION: 43200
          TIMEOUT: 43200
        run:
          dir: job-parameters
          path: sh
          args:
            - -exc
            - |
              source /assume-role

              function set_job_parameters {
                export JOB_PARAMETERS=$(cat ./parameters.txt | sed -r 's/["]+/\"/g')
              }

              function submit_job {
                pipeline_name=`cat "../meta/build_pipeline_name"`
                job_name=`cat "../meta/build_job_name"`
                build_number=`cat "../meta/build_name"`
                build_number_safe=`echo ${build_number/./-}`
                set +x
                export JOB_ID=$(aws batch submit-job --job-queue "batch_corporate_storage_coalescer" \
                  --job-definition "batch_corporate_storage_coalescer_job" \
                  --job-name "${pipeline_name}_${job_name}_${build_number_safe}" \
                  --parameters "${1}" \
                  | jq -e --raw-output .jobId)
                set -x
              }

              function wait_for_job_completion {
                i=0
                while [[ ${i} -le ${TIMEOUT} ]]
                do
                  status=$(aws batch describe-jobs --jobs ${JOB_ID} | jq -e --raw-output '.jobs[0].status')
                  case $status in
                    FAILED)
                      echo "job failed"
                      exit 1
                      ;;
                    SUCCEEDED)
                      echo "job succeeded"
                      exit 0
                      ;;
                    SUBMITTED)
                      echo "job is currently ${status}"
                      ;;
                    PENDING)
                      echo "job is currently ${status}"
                      ;;
                    RUNNABLE)
                      echo "job is currently ${status}"
                      ;;
                    STARTING)
                      echo "job is currently ${status}"
                      ;;
                    RUNNING)
                      echo "job is currently ${status}"
                      ;;
                    *)
                      echo "unknown status $status"
                      exit 1
                      ;;
                  esac
                  i=$((i+1))
                  sleep 60
                done

                echo "Timed out waiting for job to complete"
                exit 1
              }

              echo "Setting job parameters"
              set_job_parameters
              if [[ -z "${JOB_PARAMETERS}" ]]; then
                echo "Error retrieving job parameters"
                exit 1
              fi
              echo "Job parameters set to '${JOB_PARAMETERS}'"

              echo "Submitting job"
              submit_job "${JOB_PARAMETERS}"
              if [[ -z "${JOB_ID}" ]]; then
                echo "Error submitting job, empty JOB_ID received"
                exit 1
              fi
              echo "Submitted job with id of ${JOB_ID}"

              echo "Waiting for job with id of ${JOB_ID} to complete"
              wait_for_job_completion
              echo "Job with id of ${JOB_ID} completed successfully"
        inputs:
          - name: meta
          - name: job-parameters
          
    terraform-common-config:
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        params:
          TF_INPUT: false
          AWS_REGION: ((dataworks.aws_region))
          TF_CLI_ARGS_apply: -lock-timeout=300s
          TF_CLI_ARGS_plan: -lock-timeout=300s
          TF_VAR_costcode: ((dataworks.costcode))
          TF_VAR_slack_webhook_url: ((dataworks.slack_webhook_url))

    terraform-bootstrap:
      task: terraform-bootstrap
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: dwpdigital/jinja-yaml-aws
            version: 0.0.19
            tag: 0.0.19
        run:
          path: sh
          args:
            - -exc
            - |
              python bootstrap_terraform.py
              cp terraform.tf ../terraform-bootstrap
          dir: dataworks-aws-ingest-consumers
        inputs:
          - name: dataworks-aws-ingest-consumers
        outputs:
          - name: terraform-bootstrap
      params:
        AWS_REGION: ((dataworks.aws_region))

    terraform-output-ingest:
      task: terraform-output-ingest
      .: (( inject meta-corporate-storage-coalescer.plan.terraform-common-config ))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        run:
          path: sh
          args:
            - -exc
            - |
              terraform workspace show
              terraform init
              terraform output --json > ../terraform-output-ingest/outputs.json
          dir: aws-ingestion
        inputs:
          - name: aws-ingestion
        outputs:
          - name: terraform-output-ingest

    terraform-output-ingest-consumers:
      task: terraform-output-ingest-consumers
      .: (( inject meta-corporate-storage-coalescer.plan.terraform-common-config ))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        run:
          path: sh
          args:
            - -exc
            - |
              cp ../terraform-bootstrap/terraform.tf .
              ls -la terraform.tf
              terraform workspace show
              terraform init
              terraform output --json > ../terraform-output-ingest-consumers/outputs.json
          dir: dataworks-aws-ingest-consumers
        inputs:
          - name: dataworks-aws-ingest-consumers
          - name: terraform-bootstrap
        outputs:
          - name: terraform-output-ingest-consumers

    terraform-output-internal-compute:
      task: terraform-output-internal-compute
      .: (( inject meta-corporate-storage-coalescer.plan.terraform-common-config ))
      config:
        platform: linux
        image_resource:
          type: docker-image
          source:
            repository: ((dataworks.terraform_repository))
            version: ((dataworks.terraform_version))
            tag: ((dataworks.terraform_version))
        run:
          path: sh
          args:
            - -exc
            - |
              terraform workspace show
              terraform init
              terraform output --json > ../terraform-output-internal-compute/outputs.json
          dir: aws-internal-compute
        inputs:
          - name: aws-internal-compute
        outputs:
          - name: terraform-output-internal-compute
